{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "27. BERT- Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinmayeedongre/BERT/blob/main/BERT_Amazon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5el_8SqFqVAT"
      },
      "source": [
        "\n",
        "In this notebook, You will do amazon review classification with BERT.[Download data from [this](https://www.kaggle.com/snap/amazon-fine-food-reviews/data) link]\n",
        "<pre> \n",
        "It contains 5 parts as below.  Detailed instrctions are given in the each cell. please read every comment we have written. \n",
        "    1. Preprocessing \n",
        "    2. Creating a BERT model from the Tensorflow HUB.\n",
        "    3. Tokenization\n",
        "    4. getting the pretrained embedding Vector for a given review from the BERT.\n",
        "    5. Using the embedding data apply NN and classify the reviews.\n",
        "    6. Creating a Data pipeline for BERT Model. \n",
        "\n",
        "<font size=5>instructions:</font>\n",
        "\n",
        "    1. Don't change any Grader Functions. Don't manipulate any Grader functions. \n",
        "    If you manipulate any, it will be considered as plagiarised. \n",
        "    \n",
        "    2. Please read the instructions on the code cells and markdown cells. We will explain what to write. \n",
        "    \n",
        "    3. please return outputs in the same format what we asked. Eg. Don't return List if we are asking for a numpy array.\n",
        "    \n",
        "    4. Please read the external links that we are given so that you will learn the concept behind the code that you are writing.\n",
        "    \n",
        "    5. We are giving instructions at each section if necessary, please follow them. \n",
        "\n",
        "<font size=5>Every Grader function has to return True. </font>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOtG4cf0qVAZ"
      },
      "source": [
        "#all imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OcmiHdAJqVAi",
        "outputId": "50472976-df7c-4240-ecbf-aee2d9ba912c"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBsay58AqVAo"
      },
      "source": [
        "<font size=4>Grader function 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "aTBvOKFeqVAq",
        "outputId": "590fcd23-8f99-4e50-fe1c-1fff54b76ce8"
      },
      "source": [
        "def grader_tf_version():\n",
        "    assert((tf.__version__)>'2')\n",
        "    return True\n",
        "grader_tf_version()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTWRqbrBqVAu"
      },
      "source": [
        "<pre><font size=6>Part-1: Preprocessing</font></pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "ceZBtLnKfGdW",
        "outputId": "71e17051-9c2c-4e0d-829a-bc8f68d9e535"
      },
      "source": [
        "!wget --header=\"Host: doc-00-60-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9,kn-IN;q=0.8,kn;q=0.7\" --header=\"Referer: https://drive.google.com/drive/folders/1cSxMlj_KyUEK_3ZU609oFCTkYIMLwk6s\" --header=\"Cookie: AUTH_ehm6nt1btirko8i3re3h98kdfq64bivv_nonce=8i7b1df53t3sa\" --header=\"Connection: keep-alive\" \"https://doc-00-60-docs.googleusercontent.com/docs/securesc/7v9u186075bhbu1r4phlj8d2d6omqpo8/jshp0nijipfoecvbe87ekrvajarksqfs/1599460275000/18338633539012077285/07654260302095542947/1GsD8JlAc_0yJ-1151LNr6rLw83RRUPgt?e=download&authuser=0&nonce=8i7b1df53t3sa&user=07654260302095542947&hash=2rim6jb1li71gkpms191366l85e135e7\" -c -O 'Reviews.csv'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-07 06:33:04--  https://doc-00-60-docs.googleusercontent.com/docs/securesc/7v9u186075bhbu1r4phlj8d2d6omqpo8/jshp0nijipfoecvbe87ekrvajarksqfs/1599460275000/18338633539012077285/07654260302095542947/1GsD8JlAc_0yJ-1151LNr6rLw83RRUPgt?e=download&authuser=0&nonce=8i7b1df53t3sa&user=07654260302095542947&hash=2rim6jb1li71gkpms191366l85e135e7\n",
            "Resolving doc-00-60-docs.googleusercontent.com (doc-00-60-docs.googleusercontent.com)... 74.125.140.132, 2a00:1450:400c:c08::84\n",
            "Connecting to doc-00-60-docs.googleusercontent.com (doc-00-60-docs.googleusercontent.com)|74.125.140.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘Reviews.csv’\n",
            "\n",
            "Reviews.csv             [               <=>  ] 286.96M  62.0MB/s    in 4.6s    \n",
            "\n",
            "2020-09-07 06:33:09 (62.0 MB/s) - ‘Reviews.csv’ saved [300904694]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "B3csZKDrqVAv",
        "outputId": "61b8da31-b4b8-46bb-e7d0-635936827079"
      },
      "source": [
        "#Read the dataset - Amazon fine food reviews\n",
        "reviews = pd.read_csv(r\"Reviews.csv\")\n",
        "#check the info of the dataset\n",
        "reviews.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 568454 entries, 0 to 568453\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   Id                      568454 non-null  int64 \n",
            " 1   ProductId               568454 non-null  object\n",
            " 2   UserId                  568454 non-null  object\n",
            " 3   ProfileName             568438 non-null  object\n",
            " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
            " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
            " 6   Score                   568454 non-null  int64 \n",
            " 7   Time                    568454 non-null  int64 \n",
            " 8   Summary                 568427 non-null  object\n",
            " 9   Text                    568454 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 43.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "xokNn7qZqVAz",
        "outputId": "a7f4b8ad-af3c-4721-d1ee-a51251653f6d"
      },
      "source": [
        "#get only 2 columns - Text, Score\n",
        "#drop the NAN values\n",
        "reviews =reviews.loc[:,['Text','Score']]\n",
        "\n",
        "reviews.dropna(subset=['Text','Score'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>Great for sesame chicken..this is a good if no...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>These stars are small, so you can give 10-15 o...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>These are the BEST treats for training and rew...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>I am very satisfied ,product is as advertised,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>568454 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Text  Score\n",
              "0       I have bought several of the Vitality canned d...      5\n",
              "1       Product arrived labeled as Jumbo Salted Peanut...      1\n",
              "2       This is a confection that has been around a fe...      4\n",
              "3       If you are looking for the secret ingredient i...      2\n",
              "4       Great taffy at a great price.  There was a wid...      5\n",
              "...                                                   ...    ...\n",
              "568449  Great for sesame chicken..this is a good if no...      5\n",
              "568450  I'm disappointed with the flavor. The chocolat...      2\n",
              "568451  These stars are small, so you can give 10-15 o...      5\n",
              "568452  These are the BEST treats for training and rew...      5\n",
              "568453  I am very satisfied ,product is as advertised,...      5\n",
              "\n",
              "[568454 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "6IidWQ_rwUKk",
        "outputId": "084f9dc5-be1d-4055-fef1-2bcbffb20eed"
      },
      "source": [
        "reviews[reviews[\"Score\"]==1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>My cats have been happily eating Felidae Plati...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>The candy is just red , No flavor . Just  plan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>This oatmeal is not good. Its mushy, soft, I d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Arrived in 6 days and were so stale i could no...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568402</th>\n",
              "      <td>I was disappointed in this product, as I had r...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568426</th>\n",
              "      <td>The candy is tasty, but they totally scam you ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568431</th>\n",
              "      <td>Definitely not worth buying flavored water wit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568432</th>\n",
              "      <td>I thought this soup would be more like a chill...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568433</th>\n",
              "      <td>I just bought this soup today at my local groc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52268 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Text  Score\n",
              "1       Product arrived labeled as Jumbo Salted Peanut...      1\n",
              "12      My cats have been happily eating Felidae Plati...      1\n",
              "26      The candy is just red , No flavor . Just  plan...      1\n",
              "50      This oatmeal is not good. Its mushy, soft, I d...      1\n",
              "62      Arrived in 6 days and were so stale i could no...      1\n",
              "...                                                   ...    ...\n",
              "568402  I was disappointed in this product, as I had r...      1\n",
              "568426  The candy is tasty, but they totally scam you ...      1\n",
              "568431  Definitely not worth buying flavored water wit...      1\n",
              "568432  I thought this soup would be more like a chill...      1\n",
              "568433  I just bought this soup today at my local groc...      1\n",
              "\n",
              "[52268 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GZt7pVkqVA4"
      },
      "source": [
        "#if score> 3, set score = 1\n",
        "#if score<=2, set score = 0\n",
        "#if score == 3, remove the rows. \n",
        "\n",
        "reviews.loc[reviews['Score'] <= 2, 'Score'] = 0\n",
        "reviews.loc[reviews['Score'] > 3, 'Score'] = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNDrl3hOv0g7"
      },
      "source": [
        "indexes = (reviews[reviews[\"Score\"] ==3].index)\n",
        "\n",
        "reviews.drop(indexes , inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "lSNU31VRxtZZ",
        "outputId": "577aec50-7eed-43fb-84a7-8f6b8b6c5355"
      },
      "source": [
        "reviews[\"Score\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         1\n",
              "1         0\n",
              "2         1\n",
              "3         0\n",
              "4         1\n",
              "         ..\n",
              "568449    1\n",
              "568450    0\n",
              "568451    1\n",
              "568452    1\n",
              "568453    1\n",
              "Name: Score, Length: 525814, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "YgfdpuXhi9Aj",
        "outputId": "6568eb91-b7a1-4c67-9a87-512966846d25"
      },
      "source": [
        "reviews.sort_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>Great for sesame chicken..this is a good if no...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>These stars are small, so you can give 10-15 o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>These are the BEST treats for training and rew...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>I am very satisfied ,product is as advertised,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>525814 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Text  Score\n",
              "0       I have bought several of the Vitality canned d...      1\n",
              "1       Product arrived labeled as Jumbo Salted Peanut...      0\n",
              "2       This is a confection that has been around a fe...      1\n",
              "3       If you are looking for the secret ingredient i...      0\n",
              "4       Great taffy at a great price.  There was a wid...      1\n",
              "...                                                   ...    ...\n",
              "568449  Great for sesame chicken..this is a good if no...      1\n",
              "568450  I'm disappointed with the flavor. The chocolat...      0\n",
              "568451  These stars are small, so you can give 10-15 o...      1\n",
              "568452  These are the BEST treats for training and rew...      1\n",
              "568453  I am very satisfied ,product is as advertised,...      1\n",
              "\n",
              "[525814 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "32qoQWcejuTN",
        "outputId": "7b8ecfb1-c53c-4f8c-d973-b012733a198d"
      },
      "source": [
        "reviews.Score.value_counts()[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "443777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVe8LlkrqVA6"
      },
      "source": [
        "<font size=4>Grader function 2 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "7mDXSiJpqVA7",
        "outputId": "e7d37e71-d3d0-46b3-a309-3a0289f63b6d"
      },
      "source": [
        "def grader_reviews():\n",
        "    temp_shape = (reviews.shape == (525814, 2)) and (reviews.Score.value_counts()[1]==443777)\n",
        "    assert(temp_shape == True)\n",
        "    return True\n",
        "grader_reviews()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYZ-UB9UqVA-"
      },
      "source": [
        "def get_wordlen(x):\n",
        "    return len(x.split())\n",
        "reviews['len'] = reviews.Text.apply(get_wordlen)\n",
        "reviews = reviews[reviews.len<50]\n",
        "reviews = reviews.sample(n=100000, random_state=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvldQriGqVBB"
      },
      "source": [
        "#remove HTML from the Text column and save in the Text column only\n",
        "#https://stackoverflow.com/questions/50447559/apply-html-tags-removal-to-pandas-column\n",
        "import re\n",
        "def parser(text):\n",
        "    return re.sub('<[^<]+?>', '', str(text))\n",
        "\n",
        "reviews['Text']=reviews.Text.apply(parser)\n",
        "\n",
        "#reviews['Score'] = remove_tags(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "AhfN1s2mqVBD",
        "outputId": "8cc70b9d-d61c-47a2-f386-869e80dc4646"
      },
      "source": [
        "#print head 5\n",
        "reviews.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64117</th>\n",
              "      <td>The tea was of great quality and it tasted lik...</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418112</th>\n",
              "      <td>My cat loves this.  The pellets are nice and s...</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357829</th>\n",
              "      <td>Great product. Does not completely get rid of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175872</th>\n",
              "      <td>This gum is my favorite!  I would advise every...</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178716</th>\n",
              "      <td>I also found out about this product because of...</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Text  Score  len\n",
              "64117   The tea was of great quality and it tasted lik...      1   30\n",
              "418112  My cat loves this.  The pellets are nice and s...      1   31\n",
              "357829  Great product. Does not completely get rid of ...      1   41\n",
              "175872  This gum is my favorite!  I would advise every...      1   27\n",
              "178716  I also found out about this product because of...      1   22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsYDd3okqVBF"
      },
      "source": [
        "#split the data into train and test data(20%) with Stratify sampling, random state 33, \n",
        "from sklearn.model_selection import train_test_split\n",
        "X = reviews['Text'].values\n",
        "X = pd.DataFrame(X, columns=[\"Text\"])\n",
        "Y = reviews['Score'].values\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.20,stratify=Y,random_state=33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "13HA172w5VID",
        "outputId": "60083552-764d-4c17-ec79-6d934eb20d27"
      },
      "source": [
        "print(X_train.shape,X_test.shape)\n",
        "print(Y_train.shape,Y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80000, 1) (20000, 1)\n",
            "(80000,) (20000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "-Q6OAcrOqVBI",
        "outputId": "2a91f8c2-2d28-4075-b60d-ec489297d9b0"
      },
      "source": [
        "#plot bar graphs of y_train and y_test\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas.util.testing as tm\n",
        "Y_train = pd.DataFrame(Y_train)\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.countplot(reviews['Score'],data = Y_train)\n",
        "plt.title('Train')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "M2tUmAs9GxyB",
        "outputId": "465d0410-4eca-4577-c911-dacb383ac58a"
      },
      "source": [
        "#plot bar graphs of y_train and y_test\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas.util.testing as tm\n",
        "Y_test = pd.DataFrame(Y_test)\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.countplot(reviews['Score'],data = Y_test)\n",
        "plt.title('Train')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up-z5boWqVBK"
      },
      "source": [
        "#saving to disk. if we need, we can load preprocessed data directly. \n",
        "reviews.to_csv('preprocessed.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBtqNGN9qVBM"
      },
      "source": [
        "<pre><font size=6>Part-2: Creating BERT Model</font> \n",
        "\n",
        "If you want to know more about BERT, You can watch live sessions on Transformers and BERt. \n",
        "we will strongly recommend you to read <a href=\"https://jalammar.github.io/illustrated-transformer/\">Transformers</a>, <a href=\"https://arxiv.org/abs/1810.04805\">BERT Paper</a> and, <a href=\"https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\">This blog</a>.\n",
        "\n",
        "\n",
        "For this assignment, we are using <a href=\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\">BERT uncased Base model</a>. \n",
        "It uses L=12 hidden layers (i.e., Transformer blocks), a hidden size of H=768, and A=12 attention heads. </pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8xd2HejqVBN"
      },
      "source": [
        "## Loading the Pretrained Model from tensorflow HUB\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# maximum length of a seq in the data we have, for now i am making it as 55. You can change this\n",
        "max_seq_length = 55\n",
        "\n",
        "#BERT takes 3 inputs\n",
        "\n",
        "#this is input words. Sequence of words represented as integers\n",
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "\n",
        "#mask vector if you are padding anything\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
        "\n",
        "#segment vectors. If you are giving only one sentence for the classification, total seg vector is 0. \n",
        "#If you are giving two sentenced with [sep] token separated, first seq segment vectors are zeros and \n",
        "#second seq segment vector are 1's\n",
        "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "#bert layer \n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "#Bert model\n",
        "#We are using only pooled output not sequence out. \n",
        "#If you want to know about those, please read https://www.kaggle.com/questions-and-answers/86510\n",
        "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "lQJsjg6fqVBQ",
        "outputId": "24a45d7b-5b76-4a74-d4f5-b3d08f48f6f5"
      },
      "source": [
        "bert_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 55)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 55)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 55)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 109,482,241\n",
            "Trainable params: 0\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "w3z0OMA5qVBS",
        "outputId": "1f03cd65-cadb-4fae-e612-f4cfc50d0d9c"
      },
      "source": [
        "bert_model.output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'keras_layer/StatefulPartitionedCall:0' shape=(None, 768) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewv4hFCsqVBU"
      },
      "source": [
        "<pre><font size=6>Part-3: Tokenization</font></pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX3VEFjiqVBU"
      },
      "source": [
        "#getting Vocab file\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "Y_iPwa99qVBW",
        "outputId": "bf0d2175-fe6f-4d31-8742-a8b0b1d68419"
      },
      "source": [
        "!wget --header=\"Host: doc-0g-2g-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9,kn-IN;q=0.8,kn;q=0.7\" --header=\"Referer: https://drive.google.com/drive/folders/1cSxMlj_KyUEK_3ZU609oFCTkYIMLwk6s\" --header=\"Cookie: AUTH_ehm6nt1btirko8i3re3h98kdfq64bivv=07654260302095542947|1599460275000|0umc1ilbmv7i4j9lhnau8iquahju1f55; AUTH_ehm6nt1btirko8i3re3h98kdfq64bivv_nonce=cirklce0aaap4\" --header=\"Connection: keep-alive\" \"https://doc-0g-2g-docs.googleusercontent.com/docs/securesc/7v9u186075bhbu1r4phlj8d2d6omqpo8/bn4insh0k86qnib0n0jvdrifmctuc29v/1599460575000/00484516897554883881/07654260302095542947/13exfXiyiByluh1PfYK1EyZyizqxeCVG9?e=download&authuser=0&nonce=cirklce0aaap4&user=07654260302095542947&hash=fo1qsba37sf1t20hqmdqkipo6lcagovb\" -c -O 'tokenization.py'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-07 06:36:49--  https://doc-0g-2g-docs.googleusercontent.com/docs/securesc/7v9u186075bhbu1r4phlj8d2d6omqpo8/bn4insh0k86qnib0n0jvdrifmctuc29v/1599460575000/00484516897554883881/07654260302095542947/13exfXiyiByluh1PfYK1EyZyizqxeCVG9?e=download&authuser=0&nonce=cirklce0aaap4&user=07654260302095542947&hash=fo1qsba37sf1t20hqmdqkipo6lcagovb\n",
            "Resolving doc-0g-2g-docs.googleusercontent.com (doc-0g-2g-docs.googleusercontent.com)... 74.125.140.132, 2a00:1450:400c:c08::84\n",
            "Connecting to doc-0g-2g-docs.googleusercontent.com (doc-0g-2g-docs.googleusercontent.com)|74.125.140.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17318 (17K) [text/x-python]\n",
            "Saving to: ‘tokenization.py’\n",
            "\n",
            "tokenization.py     100%[===================>]  16.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-09-07 06:36:50 (63.3 MB/s) - ‘tokenization.py’ saved [17318/17318]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "fAVEXNeFhXxc",
        "outputId": "04ba52a2-b7fd-485a-978a-fa38ef4eedf2"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 22.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 4.6MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 5.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 6.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 6.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 7.0MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 6.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143kB 6.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153kB 6.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 163kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 174kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 184kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 204kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 215kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 225kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 235kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 245kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 256kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 266kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 276kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 286kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 296kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 307kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 317kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 327kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 337kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 348kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 358kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 368kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 378kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 389kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 409kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 419kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 430kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 440kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 450kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 460kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 471kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 481kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 491kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 501kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 512kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 522kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 532kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 542kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 552kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 563kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 573kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 583kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 593kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 604kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 614kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 624kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 634kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 645kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 655kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 665kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 675kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 686kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 696kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 706kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 716kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 727kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 737kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 747kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 757kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 768kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 778kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 788kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 798kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 808kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 819kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 829kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 839kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 849kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 860kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 870kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 880kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 890kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 901kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 911kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 921kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 931kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 942kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 952kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 962kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 972kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 983kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 993kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0MB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.0MB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 6.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guJMLJ8bqVBY"
      },
      "source": [
        "# Create tokenizer \" Instantiate FullTokenizer\" \n",
        "# name must be \"tokenizer\"\n",
        "# the FullTokenizer takes two parameters 1. vocab_file and 2. do_lower_case \n",
        "import tokenization \n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
        "# we have created these in the above cell ex: FullTokenizer(vocab_file, do_lower_case )\n",
        "# please check the \"tokenization.py\" file the complete implementation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKkGLhR-qVBd"
      },
      "source": [
        "<font size=4>Grader function 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2CPu850xqVBe",
        "outputId": "171d0cb7-4102-4d58-d86b-bfb5623a30be"
      },
      "source": [
        "#it has to give no error \n",
        "def grader_tokenize(tokenizer):\n",
        "    out = False\n",
        "    try:\n",
        "        out=('[CLS]' in tokenizer.vocab) and ('[SEP]' in tokenizer.vocab)\n",
        "    except:\n",
        "        out = False\n",
        "    assert(out==True)\n",
        "    return out\n",
        "grader_tokenize(tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "MIFEiuT9gLHj",
        "outputId": "e8663ae8-172f-470e-9673-b1b1dfb3aa4f"
      },
      "source": [
        "X_train.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25426</th>\n",
              "      <td>I had never tried this brand before, so I was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98503</th>\n",
              "      <td>I love these for a snack. I get a nice taste o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60439</th>\n",
              "      <td>This is my favorite store bought cookie. Crumb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78009</th>\n",
              "      <td>I must be spoiled because this coffee was very...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43615</th>\n",
              "      <td>the tins are much smaller than I expected.  bu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Text\n",
              "25426  I had never tried this brand before, so I was ...\n",
              "98503  I love these for a snack. I get a nice taste o...\n",
              "60439  This is my favorite store bought cookie. Crumb...\n",
              "78009  I must be spoiled because this coffee was very...\n",
              "43615  the tins are much smaller than I expected.  bu..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbO_Re2NMCk6"
      },
      "source": [
        "def token_names(X_tokens1):\n",
        "  X_tokens2=[]\n",
        "  for i in X_tokens1:\n",
        "    l1=[]\n",
        "    if (len(i) > 55):\n",
        "    \n",
        "      j= i[0:54]\n",
        "      k = [\"[SEP]\"]\n",
        "      m = list(np.ones(55))\n",
        "      X_tokens2.append(j+k)\n",
        "    elif (len(i) < 55):\n",
        "      j = len(i)\n",
        "      k = 55 - j-1\n",
        "      l = i[0:j-1]\n",
        "      pad =[]\n",
        "      for m in range(0,k+1):\n",
        "        pad.append(\"[PAD]\")\n",
        "      pad = pad + [\"[SEP]\"]\n",
        "      for n in pad:\n",
        "        l.append(n)\n",
        "      X_tokens2.append(l)\n",
        "      j1 = j-1\n",
        "    \n",
        "    elif (len(i) == 55):\n",
        "      X_tokens2.append(i)\n",
        "  return(X_tokens2)\n",
        "\n",
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids\n",
        "\n",
        "def get_masks(tokens, max_seq_length):\n",
        "   \n",
        "    mask =[]\n",
        "    for i in range(len(tokens)):\n",
        "      if (tokens[i] == \"[PAD]\"):\n",
        "        mask.append(0)\n",
        "      else:\n",
        "        mask.append(1)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def get_segments(tokens, max_seq_length):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9crhPylQqVBg"
      },
      "source": [
        "# Create train and test tokens (X_train_tokens, X_test_tokens) from (X_train, X_test) using Tokenizer and \n",
        "#\n",
        "X_train_to= X_train['Text'].apply(tokenizer.tokenize)\n",
        "X_test_to = X_test['Text'].apply(tokenizer.tokenize)\n",
        "# add '[CLS]' at start of the Tokens and '[SEP]' at the end of the tokens. \n",
        "X_train_tokens1=[]\n",
        "for i in X_train_to:\n",
        "  X_t =  [\"[CLS]\"] + i + [\"[SEP]\"]\n",
        "  X_train_tokens1.append(X_t)\n",
        "\n",
        "X_test_tokens1=[]\n",
        "for i in X_test_to:\n",
        "  X_t =  [\"[CLS]\"] + i + [\"[SEP]\"]\n",
        "  X_test_tokens1.append(X_t)\n",
        "# maximum number of tokens is 55(We already given this to BERT layer above) so shape is (None, 55)\n",
        "X_token_name_train =token_names(X_train_tokens1)\n",
        "X_token_name_test = token_names(X_test_tokens1)\n",
        "\n",
        "# if it is less than 55, add '[PAD]' token else truncate the tokens length.(similar to padding)\n",
        "X_train_tokens=[]\n",
        "for i in range(len(X_token_name_train)):\n",
        "  X_train_tokens.append(np.asarray(get_ids(X_token_name_train[i],tokenizer,55)))\n",
        "X_train_tokens= np.asarray(X_train_tokens)\n",
        "#print(X_train_tokens)\n",
        "\n",
        "X_test_tokens=[]\n",
        "for i in range(len(X_token_name_test)):\n",
        "  X_test_tokens.append(np.asarray(get_ids(X_token_name_test[i],tokenizer,55)))\n",
        "X_test_tokens= np.asarray(X_test_tokens)\n",
        "# Based on padding, create the mask for Train and Test ( 1 for real token, 0 for '[PAD]'), \n",
        "# it will also same shape as input tokens (None, 55) save those in X_train_mask, X_test_mask\n",
        "X_train_mask =[]\n",
        "for i in range(len(X_train_tokens)):\n",
        "  X_train_mask.append(np.asarray(get_masks(X_token_name_train[i], 55)))\n",
        "X_train_mask = np.asarray(X_train_mask)\n",
        "\n",
        "X_test_mask =[]\n",
        "for i in range(len(X_test_tokens)):\n",
        "  X_test_mask.append(np.asarray(get_masks(X_token_name_test[i], 55)))\n",
        "X_test_mask = np.asarray(X_test_mask)\n",
        "# Create a segment input for train and test. We are using only one sentence so all zeros. This shape will also (None, 55)\n",
        "\n",
        "X_train_segment=[]\n",
        "for i in range(len(X_token_name_train)):\n",
        "  X_train_segment.append(np.asarray(get_segments(X_token_name_train[i], 55)))\n",
        "X_train_segment = np.asarray(X_train_segment)  \n",
        "\n",
        "X_test_segment=[]\n",
        "for i in range(len(X_token_name_test)):\n",
        "  X_test_segment.append(np.asarray(get_segments(X_token_name_test[i], 55)))\n",
        "X_test_segment = np.asarray(X_test_segment) \n",
        "# type of all the above arrays should be numpy arrays\n",
        "\n",
        "# after execution of this cell, you have to get \n",
        "# X_train_tokens, X_train_mask, X_train_segment\n",
        "# X_test_tokens, X_test_mask, X_test_segment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2qekOc0FCGh"
      },
      "source": [
        "while(1):\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv1-t4OjqVBj"
      },
      "source": [
        "#### Example\n",
        "<img src='https://i.imgur.com/5AhhmgU.png'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxhggBxwqVBj"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF0idMRDqVBm"
      },
      "source": [
        "##save all your results to disk so that, no need to run all again. \n",
        "pickle.dump((X_train, X_train_tokens, X_train_mask, X_train_segment, Y_train),open('train_data.pkl','wb'))\n",
        "pickle.dump((X_test, X_test_tokens, X_test_mask, X_test_segment, Y_test),open('test_data.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Leu1URGzqVBo"
      },
      "source": [
        "#you can load from disk\n",
        "#X_train, X_train_tokens, X_train_mask, X_train_segment, y_train = pickle.load(open(\"train_data.pkl\", 'rb')) \n",
        "#X_test, X_test_tokens, X_test_mask, X_test_segment, y_test = pickle.load(open(\"test_data.pkl\", 'rb')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjPv8VkJqVBr"
      },
      "source": [
        "<font size=4>Grader function 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "qekHJgmdqVBs",
        "outputId": "9e0392e8-2732-4793-f3dc-8327dd716e66"
      },
      "source": [
        "def grader_alltokens_train():\n",
        "    out = False\n",
        "    \n",
        "    if type(X_train_tokens) == np.ndarray:\n",
        "        \n",
        "        temp_shapes = (X_train_tokens.shape[1]==max_seq_length) and (X_train_mask.shape[1]==max_seq_length) and \\\n",
        "        (X_train_segment.shape[1]==max_seq_length)\n",
        "        \n",
        "        segment_temp = not np.any(X_train_segment)\n",
        "        \n",
        "        mask_temp = np.sum(X_train_mask==0) == np.sum(X_train_tokens==0)\n",
        "        \n",
        "        no_cls = np.sum(X_train_tokens==tokenizer.vocab['[CLS]'])==X_train_tokens.shape[0]\n",
        "        \n",
        "        no_sep = np.sum(X_train_tokens==tokenizer.vocab['[SEP]'])==X_train_tokens.shape[0]\n",
        "        \n",
        "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
        "      \n",
        "    else:\n",
        "        print('Type of all above token arrays should be numpy array not list')\n",
        "        out = False\n",
        "    assert(out==True)\n",
        "    return out\n",
        "\n",
        "grader_alltokens_train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnvC6X_wqVBu"
      },
      "source": [
        "<font size=4>Grader function 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Av4SRMPSqVBv",
        "outputId": "abcd0cdc-8e18-4b14-c47c-79376c5346b8"
      },
      "source": [
        "def grader_alltokens_test():\n",
        "    out = False\n",
        "    if type(X_test_tokens) == np.ndarray:\n",
        "        \n",
        "        temp_shapes = (X_test_tokens.shape[1]==max_seq_length) and (X_test_mask.shape[1]==max_seq_length) and \\\n",
        "        (X_test_segment.shape[1]==max_seq_length)\n",
        "        \n",
        "        segment_temp = not np.any(X_test_segment)\n",
        "        \n",
        "        mask_temp = np.sum(X_test_mask==0) == np.sum(X_test_tokens==0)\n",
        "        \n",
        "        no_cls = np.sum(X_test_tokens==tokenizer.vocab['[CLS]'])==X_test_tokens.shape[0]\n",
        "        \n",
        "        no_sep = np.sum(X_test_tokens==tokenizer.vocab['[SEP]'])==X_test_tokens.shape[0]\n",
        "        \n",
        "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
        "      \n",
        "    else:\n",
        "        print('Type of all above token arrays should be numpy array not list')\n",
        "        out = False\n",
        "    assert(out==True)\n",
        "    return out\n",
        "grader_alltokens_test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEj-Eua5qVBx"
      },
      "source": [
        "<pre><font size=6>Part-4: Getting Embeddings from BERT Model</font>\n",
        "We already created the BERT model in the part-2 and input data in the part-3. \n",
        "We will utlize those two and will get the embeddings for each sentence in the \n",
        "Train and test data.</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "QwOVgQFDqVBy",
        "outputId": "83950936-6108-4e84-b906-0f075a6f79d7"
      },
      "source": [
        "bert_model.input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'input_word_ids:0' shape=(None, 55) dtype=int32>,\n",
              " <tf.Tensor 'input_mask:0' shape=(None, 55) dtype=int32>,\n",
              " <tf.Tensor 'segment_ids:0' shape=(None, 55) dtype=int32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ZcpkQq1OqVB0",
        "outputId": "d594fe4a-141b-4615-bda2-fda80505dac6"
      },
      "source": [
        "bert_model.output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'keras_layer/StatefulPartitionedCall:0' shape=(None, 768) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxdIlOIBlm7j"
      },
      "source": [
        "# get the train output, BERT model will give one output so save in\n",
        "# X_train_pooled_output\n",
        "X_train_pooled_output=bert_model.predict([X_train_tokens,X_train_mask,X_train_segment])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZT11BCol4gL"
      },
      "source": [
        "# get the test output, BERT model will give one output so save in\n",
        "# X_test_pooled_output\n",
        "X_test_pooled_output=bert_model.predict([X_test_tokens,X_test_mask,X_test_segment])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL6JVojfqVB8"
      },
      "source": [
        "##save all your results to disk so that, no need to run all again. \n",
        "pickle.dump((X_train_pooled_output, X_test_pooled_output),open('final_output.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSQcBdROqVB9"
      },
      "source": [
        "#X_train_pooled_output, X_test_pooled_output= pickle.load(open('final_output.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulEXFE7aqVCA"
      },
      "source": [
        "<font size=4>Grader function 6 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "oHCsW0IvqVCB",
        "outputId": "d161ba92-87ca-49a7-ac95-a741acda587c"
      },
      "source": [
        "#now we have X_train_pooled_output, y_train\n",
        "#X_test_pooled_ouput, y_test\n",
        "\n",
        "#please use this grader to evaluate\n",
        "def greader_output():\n",
        "    assert(X_train_pooled_output.shape[1]==768)\n",
        "    assert(len(Y_train)==len(X_train_pooled_output))\n",
        "    assert(X_test_pooled_output.shape[1]==768)\n",
        "    assert(len(Y_test)==len(X_test_pooled_output))\n",
        "    assert(len(Y_train.shape)==1)\n",
        "    assert(len(X_train_pooled_output.shape)==2)\n",
        "    assert(len(Y_test.shape)==1)\n",
        "    assert(len(X_test_pooled_output.shape)==2)\n",
        "    return True\n",
        "greader_output()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYwS1QbAqVCD"
      },
      "source": [
        "<pre><font size=6>Part-5: Training a NN with 768 features</font>\n",
        "\n",
        "Create a NN and train the NN. \n",
        "1.<b> You have to use AUC as metric.</b> \n",
        "2. You can use any architecture you want. \n",
        "3. You have to use tensorboard to log all your metrics and Losses. You have to send those logs. \n",
        "4. Print the loss and metric at every epoch. \n",
        "5. You have to submit without overfitting and underfitting. \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od8PQlYRqVCE"
      },
      "source": [
        "##imports\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "DtTFfpy4he0n",
        "outputId": "0d023985-c5fe-44f6-df23-257a6f9d7f36"
      },
      "source": [
        "X_train_pooled_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSnmX3WnqVCG"
      },
      "source": [
        "##create an NN and \n",
        "#x = X_train_pooled_output\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "input = layers.Input(shape=(768))\n",
        "\n",
        "x = Dense(768,activation=\"relu\",kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.001))(input)\n",
        "x = Dropout(rate=0.5)(x)\n",
        "\n",
        "x = Dense(384,activation=\"relu\", kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "x=Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(192,activation=\"relu\", kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "x=Dropout(0.5)(x)\n",
        "\n",
        "output = Dense(2, activation='softmax', kernel_initializer=\"glorot_uniform\",name='output')(x)\n",
        "\n",
        "model_1 = Model(inputs=[input],outputs=[output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "rDMPvUrib1BJ",
        "outputId": "d3dcf25e-0ab0-4c41-f126-651280f11941"
      },
      "source": [
        "model_1.compile(optimizer=optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy',auc])\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 768)               590592    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 384)               295296    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 192)               73920     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 192)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 2)                 386       \n",
            "=================================================================\n",
            "Total params: 960,194\n",
            "Trainable params: 960,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-rTDrdbsw7y"
      },
      "source": [
        "import keras\n",
        "#y_train = keras.utils.to_categorical(Y_train,num_classes= 2)\n",
        "#y_test = keras.utils.to_categorical(Y_test,num_classes= 2)\n",
        "\n",
        "y_train = pd.get_dummies(Y_train)\n",
        "y_test = pd.get_dummies(Y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdyfJIEJs9Pw"
      },
      "source": [
        "from sklearn import metrics\n",
        "def auc(y_true, y_pred):\n",
        "    return tf.py_function(metrics.roc_auc_score, (y_true, y_pred), tf.double)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOMCPduTft5I"
      },
      "source": [
        "#**Callback,Early stopping and checkpoint**\n",
        "import os\n",
        "import datetime\n",
        "import keras\n",
        "checkpoint_1 = keras.callbacks.ModelCheckpoint('model_1.hdf5', save_best_only= True, monitor='val_auc', mode = 'max', verbose= 1)\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_auc', mode= 'max', verbose=1, patience=8)\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vjwVCsiffznI",
        "outputId": "73702ed5-350b-4f0d-c9bd-a12930af0c3d"
      },
      "source": [
        "history_1 = model_1.fit(X_train_pooled_output,y_train,batch_size=512,epochs=100,verbose=2,validation_data=(X_test_pooled_output,y_test),callbacks=[checkpoint_1,early_stop,tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0691s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0691s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_auc improved from -inf to 0.80126, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 2.8722 - accuracy: 0.8565 - auc: 0.5628 - val_loss: 2.5620 - val_accuracy: 0.8701 - val_auc: 0.8013\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_auc improved from 0.80126 to 0.86039, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 2.3488 - accuracy: 0.8706 - auc: 0.7470 - val_loss: 2.1215 - val_accuracy: 0.8785 - val_auc: 0.8604\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_auc improved from 0.86039 to 0.90493, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 1.9713 - accuracy: 0.8813 - auc: 0.8516 - val_loss: 1.7933 - val_accuracy: 0.8960 - val_auc: 0.9049\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_auc improved from 0.90493 to 0.92515, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 1.6894 - accuracy: 0.8939 - auc: 0.8933 - val_loss: 1.5507 - val_accuracy: 0.9094 - val_auc: 0.9251\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_auc improved from 0.92515 to 0.93498, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 1.4716 - accuracy: 0.9048 - auc: 0.9130 - val_loss: 1.3594 - val_accuracy: 0.9143 - val_auc: 0.9350\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_auc improved from 0.93498 to 0.93937, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 1.3024 - accuracy: 0.9096 - auc: 0.9216 - val_loss: 1.2078 - val_accuracy: 0.9186 - val_auc: 0.9394\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_auc improved from 0.93937 to 0.94182, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 1.1622 - accuracy: 0.9119 - auc: 0.9289 - val_loss: 1.0827 - val_accuracy: 0.9207 - val_auc: 0.9418\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_auc improved from 0.94182 to 0.94243, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 1.0456 - accuracy: 0.9154 - auc: 0.9314 - val_loss: 0.9804 - val_accuracy: 0.9201 - val_auc: 0.9424\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_auc improved from 0.94243 to 0.94510, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.9458 - accuracy: 0.9175 - auc: 0.9357 - val_loss: 0.8927 - val_accuracy: 0.9204 - val_auc: 0.9451\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_auc improved from 0.94510 to 0.94568, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.8611 - accuracy: 0.9181 - auc: 0.9368 - val_loss: 0.8107 - val_accuracy: 0.9243 - val_auc: 0.9457\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_auc improved from 0.94568 to 0.94600, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.7884 - accuracy: 0.9199 - auc: 0.9382 - val_loss: 0.7520 - val_accuracy: 0.9195 - val_auc: 0.9460\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_auc improved from 0.94600 to 0.94799, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.7261 - accuracy: 0.9200 - auc: 0.9394 - val_loss: 0.6879 - val_accuracy: 0.9242 - val_auc: 0.9480\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_auc improved from 0.94799 to 0.94867, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.6717 - accuracy: 0.9217 - auc: 0.9411 - val_loss: 0.6360 - val_accuracy: 0.9263 - val_auc: 0.9487\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_auc did not improve from 0.94867\n",
            "157/157 - 1s - loss: 0.6232 - accuracy: 0.9218 - auc: 0.9428 - val_loss: 0.5942 - val_accuracy: 0.9247 - val_auc: 0.9485\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_auc improved from 0.94867 to 0.94871, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.5845 - accuracy: 0.9216 - auc: 0.9429 - val_loss: 0.5631 - val_accuracy: 0.9202 - val_auc: 0.9487\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_auc improved from 0.94871 to 0.94926, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.5453 - accuracy: 0.9239 - auc: 0.9448 - val_loss: 0.5250 - val_accuracy: 0.9261 - val_auc: 0.9493\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_auc improved from 0.94926 to 0.95006, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.5168 - accuracy: 0.9234 - auc: 0.9438 - val_loss: 0.4931 - val_accuracy: 0.9275 - val_auc: 0.9501\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_auc improved from 0.95006 to 0.95107, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.4909 - accuracy: 0.9237 - auc: 0.9450 - val_loss: 0.4672 - val_accuracy: 0.9290 - val_auc: 0.9511\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_auc improved from 0.95107 to 0.95108, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.4666 - accuracy: 0.9241 - auc: 0.9463 - val_loss: 0.4488 - val_accuracy: 0.9272 - val_auc: 0.9511\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_auc improved from 0.95108 to 0.95153, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.4464 - accuracy: 0.9242 - auc: 0.9469 - val_loss: 0.4356 - val_accuracy: 0.9247 - val_auc: 0.9515\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_auc did not improve from 0.95153\n",
            "157/157 - 1s - loss: 0.4298 - accuracy: 0.9252 - auc: 0.9468 - val_loss: 0.4196 - val_accuracy: 0.9254 - val_auc: 0.9512\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_auc improved from 0.95153 to 0.95188, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.4144 - accuracy: 0.9258 - auc: 0.9477 - val_loss: 0.4029 - val_accuracy: 0.9270 - val_auc: 0.9519\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_auc improved from 0.95188 to 0.95248, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.4004 - accuracy: 0.9260 - auc: 0.9480 - val_loss: 0.3912 - val_accuracy: 0.9269 - val_auc: 0.9525\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_auc did not improve from 0.95248\n",
            "157/157 - 1s - loss: 0.3903 - accuracy: 0.9260 - auc: 0.9483 - val_loss: 0.3873 - val_accuracy: 0.9237 - val_auc: 0.9520\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_auc improved from 0.95248 to 0.95274, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.3809 - accuracy: 0.9260 - auc: 0.9488 - val_loss: 0.3682 - val_accuracy: 0.9312 - val_auc: 0.9527\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_auc improved from 0.95274 to 0.95305, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.3731 - accuracy: 0.9258 - auc: 0.9488 - val_loss: 0.3624 - val_accuracy: 0.9291 - val_auc: 0.9531\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_auc did not improve from 0.95305\n",
            "157/157 - 1s - loss: 0.3645 - accuracy: 0.9266 - auc: 0.9495 - val_loss: 0.3543 - val_accuracy: 0.9299 - val_auc: 0.9530\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_auc did not improve from 0.95305\n",
            "157/157 - 1s - loss: 0.3585 - accuracy: 0.9257 - auc: 0.9501 - val_loss: 0.3614 - val_accuracy: 0.9232 - val_auc: 0.9526\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_auc improved from 0.95305 to 0.95403, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.3505 - accuracy: 0.9276 - auc: 0.9501 - val_loss: 0.3428 - val_accuracy: 0.9291 - val_auc: 0.9540\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_auc did not improve from 0.95403\n",
            "157/157 - 1s - loss: 0.3455 - accuracy: 0.9278 - auc: 0.9502 - val_loss: 0.3359 - val_accuracy: 0.9307 - val_auc: 0.9539\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_auc did not improve from 0.95403\n",
            "157/157 - 1s - loss: 0.3401 - accuracy: 0.9281 - auc: 0.9510 - val_loss: 0.3312 - val_accuracy: 0.9320 - val_auc: 0.9536\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_auc improved from 0.95403 to 0.95453, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.3366 - accuracy: 0.9277 - auc: 0.9508 - val_loss: 0.3271 - val_accuracy: 0.9312 - val_auc: 0.9545\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_auc improved from 0.95453 to 0.95457, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.3324 - accuracy: 0.9281 - auc: 0.9509 - val_loss: 0.3238 - val_accuracy: 0.9316 - val_auc: 0.9546\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_auc did not improve from 0.95457\n",
            "157/157 - 1s - loss: 0.3301 - accuracy: 0.9273 - auc: 0.9510 - val_loss: 0.3235 - val_accuracy: 0.9302 - val_auc: 0.9541\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_auc did not improve from 0.95457\n",
            "157/157 - 1s - loss: 0.3255 - accuracy: 0.9278 - auc: 0.9514 - val_loss: 0.3173 - val_accuracy: 0.9323 - val_auc: 0.9541\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_auc improved from 0.95457 to 0.95490, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.3226 - accuracy: 0.9275 - auc: 0.9517 - val_loss: 0.3136 - val_accuracy: 0.9323 - val_auc: 0.9549\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_auc improved from 0.95490 to 0.95520, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.3184 - accuracy: 0.9290 - auc: 0.9520 - val_loss: 0.3101 - val_accuracy: 0.9328 - val_auc: 0.9552\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_auc did not improve from 0.95520\n",
            "157/157 - 1s - loss: 0.3167 - accuracy: 0.9289 - auc: 0.9519 - val_loss: 0.3098 - val_accuracy: 0.9309 - val_auc: 0.9548\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_auc did not improve from 0.95520\n",
            "157/157 - 1s - loss: 0.3137 - accuracy: 0.9287 - auc: 0.9523 - val_loss: 0.3169 - val_accuracy: 0.9258 - val_auc: 0.9545\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_auc improved from 0.95520 to 0.95548, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.3126 - accuracy: 0.9282 - auc: 0.9521 - val_loss: 0.3075 - val_accuracy: 0.9284 - val_auc: 0.9555\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_auc improved from 0.95548 to 0.95580, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.3087 - accuracy: 0.9286 - auc: 0.9535 - val_loss: 0.3024 - val_accuracy: 0.9326 - val_auc: 0.9558\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_auc did not improve from 0.95580\n",
            "157/157 - 1s - loss: 0.3079 - accuracy: 0.9280 - auc: 0.9521 - val_loss: 0.2987 - val_accuracy: 0.9324 - val_auc: 0.9552\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_auc did not improve from 0.95580\n",
            "157/157 - 1s - loss: 0.3054 - accuracy: 0.9287 - auc: 0.9532 - val_loss: 0.2984 - val_accuracy: 0.9339 - val_auc: 0.9553\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_auc did not improve from 0.95580\n",
            "157/157 - 1s - loss: 0.3021 - accuracy: 0.9288 - auc: 0.9523 - val_loss: 0.2958 - val_accuracy: 0.9325 - val_auc: 0.9555\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_auc improved from 0.95580 to 0.95584, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.3013 - accuracy: 0.9282 - auc: 0.9521 - val_loss: 0.2959 - val_accuracy: 0.9312 - val_auc: 0.9558\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_auc improved from 0.95584 to 0.95612, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.3020 - accuracy: 0.9275 - auc: 0.9526 - val_loss: 0.2917 - val_accuracy: 0.9328 - val_auc: 0.9561\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_auc did not improve from 0.95612\n",
            "157/157 - 1s - loss: 0.2979 - accuracy: 0.9286 - auc: 0.9531 - val_loss: 0.2896 - val_accuracy: 0.9335 - val_auc: 0.9554\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_auc did not improve from 0.95612\n",
            "157/157 - 1s - loss: 0.2949 - accuracy: 0.9290 - auc: 0.9535 - val_loss: 0.2883 - val_accuracy: 0.9327 - val_auc: 0.9551\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_auc improved from 0.95612 to 0.95624, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.2932 - accuracy: 0.9291 - auc: 0.9535 - val_loss: 0.2958 - val_accuracy: 0.9277 - val_auc: 0.9562\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_auc did not improve from 0.95624\n",
            "157/157 - 1s - loss: 0.2920 - accuracy: 0.9291 - auc: 0.9538 - val_loss: 0.2879 - val_accuracy: 0.9312 - val_auc: 0.9558\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_auc did not improve from 0.95624\n",
            "157/157 - 1s - loss: 0.2903 - accuracy: 0.9287 - auc: 0.9544 - val_loss: 0.2829 - val_accuracy: 0.9331 - val_auc: 0.9553\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_auc did not improve from 0.95624\n",
            "157/157 - 1s - loss: 0.2896 - accuracy: 0.9283 - auc: 0.9534 - val_loss: 0.2807 - val_accuracy: 0.9334 - val_auc: 0.9562\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_auc did not improve from 0.95624\n",
            "157/157 - 1s - loss: 0.2859 - accuracy: 0.9295 - auc: 0.9544 - val_loss: 0.2792 - val_accuracy: 0.9334 - val_auc: 0.9561\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_auc improved from 0.95624 to 0.95632, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.2861 - accuracy: 0.9294 - auc: 0.9537 - val_loss: 0.2808 - val_accuracy: 0.9313 - val_auc: 0.9563\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_auc improved from 0.95632 to 0.95635, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.2821 - accuracy: 0.9309 - auc: 0.9544 - val_loss: 0.2777 - val_accuracy: 0.9327 - val_auc: 0.9563\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_auc improved from 0.95635 to 0.95714, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.2827 - accuracy: 0.9295 - auc: 0.9537 - val_loss: 0.2747 - val_accuracy: 0.9343 - val_auc: 0.9571\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_auc did not improve from 0.95714\n",
            "157/157 - 2s - loss: 0.2805 - accuracy: 0.9304 - auc: 0.9546 - val_loss: 0.2758 - val_accuracy: 0.9324 - val_auc: 0.9571\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_auc did not improve from 0.95714\n",
            "157/157 - 1s - loss: 0.2778 - accuracy: 0.9297 - auc: 0.9551 - val_loss: 0.2719 - val_accuracy: 0.9346 - val_auc: 0.9571\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_auc did not improve from 0.95714\n",
            "157/157 - 1s - loss: 0.2778 - accuracy: 0.9298 - auc: 0.9546 - val_loss: 0.2729 - val_accuracy: 0.9321 - val_auc: 0.9562\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_auc improved from 0.95714 to 0.95716, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.2756 - accuracy: 0.9299 - auc: 0.9547 - val_loss: 0.2692 - val_accuracy: 0.9342 - val_auc: 0.9572\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_auc improved from 0.95716 to 0.95728, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.2761 - accuracy: 0.9300 - auc: 0.9548 - val_loss: 0.2672 - val_accuracy: 0.9346 - val_auc: 0.9573\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_auc improved from 0.95728 to 0.95732, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.2735 - accuracy: 0.9294 - auc: 0.9549 - val_loss: 0.2687 - val_accuracy: 0.9327 - val_auc: 0.9573\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_auc did not improve from 0.95732\n",
            "157/157 - 1s - loss: 0.2694 - accuracy: 0.9325 - auc: 0.9555 - val_loss: 0.2730 - val_accuracy: 0.9291 - val_auc: 0.9570\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_auc did not improve from 0.95732\n",
            "157/157 - 1s - loss: 0.2706 - accuracy: 0.9304 - auc: 0.9551 - val_loss: 0.2638 - val_accuracy: 0.9355 - val_auc: 0.9570\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_auc did not improve from 0.95732\n",
            "157/157 - 1s - loss: 0.2691 - accuracy: 0.9311 - auc: 0.9553 - val_loss: 0.2697 - val_accuracy: 0.9317 - val_auc: 0.9569\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_auc did not improve from 0.95732\n",
            "157/157 - 1s - loss: 0.2684 - accuracy: 0.9305 - auc: 0.9552 - val_loss: 0.2640 - val_accuracy: 0.9340 - val_auc: 0.9565\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_auc did not improve from 0.95732\n",
            "157/157 - 1s - loss: 0.2672 - accuracy: 0.9301 - auc: 0.9557 - val_loss: 0.2737 - val_accuracy: 0.9298 - val_auc: 0.9570\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_auc did not improve from 0.95732\n",
            "157/157 - 1s - loss: 0.2657 - accuracy: 0.9310 - auc: 0.9550 - val_loss: 0.2623 - val_accuracy: 0.9322 - val_auc: 0.9572\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_auc improved from 0.95732 to 0.95746, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.2641 - accuracy: 0.9313 - auc: 0.9551 - val_loss: 0.2627 - val_accuracy: 0.9306 - val_auc: 0.9575\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_auc did not improve from 0.95746\n",
            "157/157 - 1s - loss: 0.2633 - accuracy: 0.9305 - auc: 0.9550 - val_loss: 0.2690 - val_accuracy: 0.9289 - val_auc: 0.9572\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_auc improved from 0.95746 to 0.95765, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.2624 - accuracy: 0.9302 - auc: 0.9557 - val_loss: 0.2556 - val_accuracy: 0.9348 - val_auc: 0.9577\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_auc did not improve from 0.95765\n",
            "157/157 - 1s - loss: 0.2644 - accuracy: 0.9292 - auc: 0.9551 - val_loss: 0.2617 - val_accuracy: 0.9297 - val_auc: 0.9571\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_auc improved from 0.95765 to 0.95788, saving model to model_1.hdf5\n",
            "157/157 - 2s - loss: 0.2596 - accuracy: 0.9311 - auc: 0.9548 - val_loss: 0.2536 - val_accuracy: 0.9351 - val_auc: 0.9579\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_auc did not improve from 0.95788\n",
            "157/157 - 1s - loss: 0.2602 - accuracy: 0.9305 - auc: 0.9553 - val_loss: 0.2541 - val_accuracy: 0.9336 - val_auc: 0.9575\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_auc improved from 0.95788 to 0.95791, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.2582 - accuracy: 0.9304 - auc: 0.9550 - val_loss: 0.2625 - val_accuracy: 0.9291 - val_auc: 0.9579\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_auc did not improve from 0.95791\n",
            "157/157 - 1s - loss: 0.2592 - accuracy: 0.9301 - auc: 0.9552 - val_loss: 0.2521 - val_accuracy: 0.9344 - val_auc: 0.9575\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_auc improved from 0.95791 to 0.95823, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.2560 - accuracy: 0.9312 - auc: 0.9555 - val_loss: 0.2496 - val_accuracy: 0.9345 - val_auc: 0.9582\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_auc did not improve from 0.95823\n",
            "157/157 - 1s - loss: 0.2563 - accuracy: 0.9296 - auc: 0.9551 - val_loss: 0.2588 - val_accuracy: 0.9282 - val_auc: 0.9571\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_auc did not improve from 0.95823\n",
            "157/157 - 1s - loss: 0.2577 - accuracy: 0.9297 - auc: 0.9550 - val_loss: 0.2735 - val_accuracy: 0.9196 - val_auc: 0.9558\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_auc did not improve from 0.95823\n",
            "157/157 - 1s - loss: 0.2545 - accuracy: 0.9298 - auc: 0.9555 - val_loss: 0.2462 - val_accuracy: 0.9348 - val_auc: 0.9574\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_auc improved from 0.95823 to 0.95869, saving model to model_1.hdf5\n",
            "157/157 - 1s - loss: 0.2501 - accuracy: 0.9324 - auc: 0.9561 - val_loss: 0.2435 - val_accuracy: 0.9360 - val_auc: 0.9587\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: val_auc did not improve from 0.95869\n",
            "157/157 - 1s - loss: 0.2518 - accuracy: 0.9301 - auc: 0.9560 - val_loss: 0.2516 - val_accuracy: 0.9313 - val_auc: 0.9577\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: val_auc did not improve from 0.95869\n",
            "157/157 - 1s - loss: 0.2495 - accuracy: 0.9311 - auc: 0.9563 - val_loss: 0.2467 - val_accuracy: 0.9326 - val_auc: 0.9582\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: val_auc did not improve from 0.95869\n",
            "157/157 - 1s - loss: 0.2471 - accuracy: 0.9317 - auc: 0.9565 - val_loss: 0.2417 - val_accuracy: 0.9351 - val_auc: 0.9585\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: val_auc did not improve from 0.95869\n",
            "157/157 - 1s - loss: 0.2494 - accuracy: 0.9313 - auc: 0.9553 - val_loss: 0.2427 - val_accuracy: 0.9327 - val_auc: 0.9586\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: val_auc did not improve from 0.95869\n",
            "157/157 - 1s - loss: 0.2482 - accuracy: 0.9313 - auc: 0.9553 - val_loss: 0.2407 - val_accuracy: 0.9340 - val_auc: 0.9585\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: val_auc did not improve from 0.95869\n",
            "157/157 - 2s - loss: 0.2455 - accuracy: 0.9313 - auc: 0.9560 - val_loss: 0.2455 - val_accuracy: 0.9344 - val_auc: 0.9584\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: val_auc did not improve from 0.95869\n",
            "157/157 - 2s - loss: 0.2477 - accuracy: 0.9303 - auc: 0.9546 - val_loss: 0.2493 - val_accuracy: 0.9279 - val_auc: 0.9581\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: val_auc did not improve from 0.95869\n",
            "157/157 - 2s - loss: 0.2460 - accuracy: 0.9305 - auc: 0.9554 - val_loss: 0.2392 - val_accuracy: 0.9341 - val_auc: 0.9580\n",
            "Epoch 00089: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0h4GWrBt2hN"
      },
      "source": [
        "best_model = tf.keras.models.load_model('model_1.hdf5', custom_objects={'auc': auc}) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "qJD0xdFquCRg",
        "outputId": "aae171c0-cbc8-4c5d-d4bd-9591ee27a6e8"
      },
      "source": [
        "score = best_model.evaluate(X_test_pooled_output, y_test,batch_size=512)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 0s 7ms/step - loss: 0.2435 - accuracy: 0.9360 - auc: 0.9587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rrHR0Qp41oi"
      },
      "source": [
        "%reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFFjnMsGurpH"
      },
      "source": [
        "!kill 4414"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "MPnoq4wmuyEO",
        "outputId": "10b1a26b-c594-491a-b3d4-c01f56618f3a"
      },
      "source": [
        "%tensorboard --logdir logs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sw_mA8x8XES"
      },
      "source": [
        "while(1):\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcILeYZI9pxm"
      },
      "source": [
        "<Pre><font size=6>Part-6: Creating a Data pipeline for BERT Model</font> \n",
        "\n",
        "1. Download data from <a href=\"https://drive.google.com/file/d/1QwjqTsqTX2vdy7fTmeXjxP3dq8IAVLpo/view?usp=sharing\">here</a>\n",
        "2. Read the csv file\n",
        "3. Remove all the html tags\n",
        "4. Now do tokenization [Part 3 as mentioned above]\n",
        "    * Create tokens,mask array and segment array\n",
        "5. Get Embeddings from BERT Model [Part 4 as mentioned above] , let it be X_test\n",
        "   * Print the shape of output(X_test.shape).You should get (352,768)\n",
        "6. Predit the output of X_test with the Neural network model which we trained earlier.\n",
        "7. Print the occurences of class labels in the predicted output\n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "iiBeOnna9yDH",
        "outputId": "cc431a6f-5da9-495e-e5af-2e2ba0f62019"
      },
      "source": [
        "!wget --header=\"Host: doc-00-2g-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9,kn-IN;q=0.8,kn;q=0.7\" --header=\"Referer: https://drive.google.com/\" --header=\"Cookie: AUTH_ehm6nt1btirko8i3re3h98kdfq64bivv_nonce=kctgbv4fj9ot4\" --header=\"Connection: keep-alive\" \"https://doc-00-2g-docs.googleusercontent.com/docs/securesc/7v9u186075bhbu1r4phlj8d2d6omqpo8/6ddiva9tmaitkj9as6a3t9obvh0eus83/1599461700000/00484516897554883881/07654260302095542947/1QwjqTsqTX2vdy7fTmeXjxP3dq8IAVLpo?e=download&authuser=0&nonce=kctgbv4fj9ot4&user=07654260302095542947&hash=nf1d6mgfasar357kj5e0b6de83mfsmde\" -c -O 'test.csv'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-07 06:56:20--  https://doc-00-2g-docs.googleusercontent.com/docs/securesc/7v9u186075bhbu1r4phlj8d2d6omqpo8/6ddiva9tmaitkj9as6a3t9obvh0eus83/1599461700000/00484516897554883881/07654260302095542947/1QwjqTsqTX2vdy7fTmeXjxP3dq8IAVLpo?e=download&authuser=0&nonce=kctgbv4fj9ot4&user=07654260302095542947&hash=nf1d6mgfasar357kj5e0b6de83mfsmde\n",
            "Resolving doc-00-2g-docs.googleusercontent.com (doc-00-2g-docs.googleusercontent.com)... 74.125.140.132, 2a00:1450:400c:c08::84\n",
            "Connecting to doc-00-2g-docs.googleusercontent.com (doc-00-2g-docs.googleusercontent.com)|74.125.140.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 62100 (61K) [text/csv]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "test.csv            100%[===================>]  60.64K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-09-07 06:56:20 (105 MB/s) - ‘test.csv’ saved [62100/62100]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTBZoVH5LMpd"
      },
      "source": [
        "test_text=pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6S11xiBLumz"
      },
      "source": [
        "import re\n",
        "def parser(text):\n",
        "    return re.sub('<[^<]+?>', '', str(text))\n",
        "\n",
        "test_text['Text']=test_text.Text.apply(parser)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27-TXOeBUCI1"
      },
      "source": [
        "# Create train and test tokens (X_train_tokens, X_test_tokens) from (X_train, X_test) using Tokenizer and \n",
        "#\n",
        "\n",
        "X_test_to = test_text['Text'].apply(tokenizer.tokenize)\n",
        "# add '[CLS]' at start of the Tokens and '[SEP]' at the end of the tokens. \n",
        "\n",
        "\n",
        "X_test_tokens1=[]\n",
        "for i in X_test_to:\n",
        "  X_t =  [\"[CLS]\"] + i + [\"[SEP]\"]\n",
        "  X_test_tokens1.append(X_t)\n",
        "# maximum number of tokens is 55(We already given this to BERT layer above) so shape is (None, 55)\n",
        "\n",
        "X_token_name_test = token_names(X_test_tokens1)\n",
        "\n",
        "# if it is less than 55, add '[PAD]' token else truncate the tokens length.(similar to padding)\n",
        "\n",
        "#print(X_train_tokens)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dde80w0xUWDL"
      },
      "source": [
        "\n",
        "X_test_tokens=[]\n",
        "for i in range(len(X_token_name_test)):\n",
        "  X_test_tokens.append(np.asarray(get_ids(X_token_name_test[i],tokenizer,55)))\n",
        "X_test_tokens= np.asarray(X_test_tokens)\n",
        "# Based on padding, create the mask for Train and Test ( 1 for real token, 0 for '[PAD]'), \n",
        "# it will also same shape as input tokens (None, 55) save those in X_train_mask, X_test_mask\n",
        "\n",
        "\n",
        "X_test_mask =[]\n",
        "for i in range(len(X_test_tokens)):\n",
        "  X_test_mask.append(np.asarray(get_masks(X_token_name_test[i], 55)))\n",
        "X_test_mask = np.asarray(X_test_mask)\n",
        "# Create a segment input for train and test. We are using only one sentence so all zeros. This shape will also (None, 55)\n",
        "\n",
        "\n",
        "X_test_segment=[]\n",
        "for i in range(len(X_token_name_test)):\n",
        "  X_test_segment.append(np.asarray(get_segments(X_token_name_test[i], 55)))\n",
        "X_test_segment = np.asarray(X_test_segment) \n",
        "# type of all the above arrays should be numpy arrays\n",
        "\n",
        "# after execution of this cell, you have to get \n",
        "# X_train_tokens, X_train_mask, X_train_segment\n",
        "# X_test_tokens, X_test_mask, X_test_segment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g-_ExsAW9Du"
      },
      "source": [
        "X_pooled_output=bert_model.predict([X_test_tokens,X_test_mask,X_test_segment])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "BrPTcqUJYdZm",
        "outputId": "7f95092b-d089-49bf-f27c-f42945bc53f3"
      },
      "source": [
        "X_pooled_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkdVMxv3ZU0A"
      },
      "source": [
        "model_1.compile(optimizer=optimizers.Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy',auc])\n",
        "#ynew = model_1.predict(X_pooled_output)\n",
        "\n",
        "\n",
        "\n",
        "y =np.argmax(model_1.predict(X_pooled_output),axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "kgZOz4SydCra",
        "outputId": "7b2f4e28-9c91-454d-d349-67db10f2f26a"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l__inTANGD9x"
      },
      "source": [
        "We used BERT uncased base model to get embeddings of Train and Test data.Tokenized X train and X test were passed to BERT in order to obtain pooled output (embeddings).\n",
        "Then we pass our embeddings to Feed Forward neural network which also contains drop out layers in order to avoid overfitting.\n",
        "We need to get auc score more than 95 % , We'll early stop once we reach our requirement.\n",
        "Model is now used to predict the new test data and we obtain predicted classes."
      ]
    }
  ]
}